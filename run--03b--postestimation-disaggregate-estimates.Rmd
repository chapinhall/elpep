
```{r}
# run scripts for necessary packages and objects as necessary
if (!"chHexs"        %in% objects()) source("settings--main.R", echo = FALSE)
if (!"my_state_abbr" %in% objects()) source("settings--profile.R", echo = FALSE)
if (!"bin_age"       %in% objects()) source("method--general-helper-functions.R", echo = FALSE)
```

```{r load the data from the previous stage}
# Load prepped data
for (f in c("geo", "acs1", "cps", "acs5", "pop")) {
  load(file = glue("{output_path}{f}_data_{my_output_tag}.Rda"))
}
load(file = glue("{output_path}Now-cast counts at the tract level, pre-disaggregation - {my_output_tag}.Rda"))
```


### Disaggregate Estimates by Age Group

Our strategy to disaggregate estimates by age group--primarily to break our estimates for ages 0-5 into 0-2 and 3-5--is to take the empirical age breakdown specific to each outcome, from the ACS 1-year data. 

```{r calculate outcome-specific age breakdowns}
calc_breakdown <- function(acs1_outcome_sub, outcome_var) {
  acs1_age_breakdown <-
    acs1_outcome_sub %>% 
    filter(child_agegroup %in% c("0to2", "3to5")) %>% 
    mutate(age_0to2 = between(AGEP, 0, 2),
           age_3to5 = between(AGEP, 3, 5),
           age_4    = AGEP == 4,
           age_5    = AGEP == 5) %>% 
    summarize(age_0to2 = sum(PWGTP[age_0to2]) / sum(PWGTP),
              age_3to5 = sum(PWGTP[age_3to5]) / sum(PWGTP),
              age_4    = sum(PWGTP[age_4])    / sum(PWGTP),
              age_5    = sum(PWGTP[age_5])    / sum(PWGTP)) %>% 
    mutate(outcome_var = outcome_var)
      
  if (FALSE) {
    acs1_outcome_sub %>% 
      filter(child_agegroup %in% c("0to2", "3to5")) %>% 
      mutate(age_0to2 = between(AGEP, 0, 2),
             age_3to5 = between(AGEP, 3, 5),
             age_4    = AGEP == 4,
             age_5    = AGEP == 5) %>% 
      select(AGEP, child_agegroup, age_0to2, age_3to5, age_4, age_5) %>% 
      unique() %>% 
      arrange(AGEP)
  }
  
  return(acs1_age_breakdown)
}

age_breakdown_byoutcome <-
 bind_rows(
   calc_breakdown(acs1_child %>% filter(fam_incpov_ratio <= 0.50), "incpov_le50_post_adj"),
   calc_breakdown(acs1_child %>% filter(fam_incpov_ratio <= 1.00), "incpov_le100_post_adj"),
   calc_breakdown(acs1_child %>% filter(fam_incpov_ratio <= 1.85), "incpov_le185_post_adj"),
   calc_breakdown(acs1_child %>% filter(fam_incpov_ratio <= 2.00), "incpov_le200_post_adj"),
   calc_breakdown(acs1_child %>% filter(fam_incpov_ratio <= 2.25), "incpov_le225_post_adj"),
   calc_breakdown(acs1_child %>% filter(fam_incpov_ratio <= 4.00), "incpov_le400_post_adj"))
```


```{r add breakdowns for all relevant ccdf sensitivities}

for (ccdf_spec in unique(str_subset(nowcast_parallel_counts$outcome_var, "ccdf_elig_incratio"))) {
  
  age_breakdown_byoutcome <- 
    bind_rows(age_breakdown_byoutcome,
              calc_breakdown(acs1_child %>% filter(get(ccdf_spec) == TRUE),
                             ccdf_spec))
  
} 
```

```{r examine the age dispersion across outcomes, eval = developer_mode}

age_breakdown_byoutcome_long <- 
  age_breakdown_byoutcome %>% 
  pivot_longer(cols = -outcome_var,
               names_to = "child_agegroup",
               values_to = "pct_age_of_lt5") %>% 
  mutate(outcome_var = sort_by_char_nums(outcome_var))

plot_age_in_outcome <- function(outcome_regex, subtitle) {
  ggplot(age_breakdown_byoutcome_long %>% filter(str_detect(outcome_var, outcome_regex)),
       aes(x = child_agegroup,
           y = pct_age_of_lt5,
           fill = outcome_var)) +
  geom_bar(stat = "identity",
           position = "dodge") +
  scale_y_continuous(labels = percent) + 
  scale_fill_viridis_d(option = "H",
                       direction = -1) +
  labs(title = "Percent of Children Under 5 by Sub-Age Group, by Outcome",
       subtitle = subtitle,
       x = "",
       y = "% of children <= 5 in group") +
  theme_minimal() +
  theme(legend.position = "bottom")
}

plot_age_in_outcome("incpov", "Income-to-Poverty Outcomes")
plot_age_in_outcome("ccdf",   "CCDF Outcomes")
```

```{r merge and disaggregate tract-level estimates}
# Round age values to ensure adding-up
nowcast_parallel_counts <- 
  nowcast_parallel_counts %>% 
  mutate(count = round(count, 0)) %>% 
  data.table()

# Prep overall population for under 5 breakdown
pop_by_age_under5 <- 
  pop_by_age %>% 
  select(GEOID = GEOID_TR20, year, age_0to2 = age_0to2_count, age_3to5 = age_3to5_count) %>% 
  pivot_longer(cols = matches("age"),
               names_to = "child_agegroup",
               values_to = "pop_count")

nowcast_elig_counts_0to5 <- 
  nowcast_parallel_counts %>% 
  filter(age == "age_0to5") %>% 
  merge(age_breakdown_byoutcome_long,
        by = "outcome_var",
        all.x = TRUE,
        allow.cartesian = TRUE) %>% 
    select(-pop_count) %>% 
  merge(pop_by_age_under5,
        by = c("GEOID", "year", "child_agegroup"),
        all.x = TRUE) %>% 
  mutate(count    = pct_age_of_lt5 * count,
         count_se = pct_age_of_lt5 * count_se) %>% 
  select(-age, age = child_agegroup)

nowcast_elig_counts_added_ages <- 
  bind_rows(nowcast_elig_counts_0to5,
            nowcast_parallel_counts) %>% 
  select(outcome_var, GEOID, cps_base_recency, pd, year, age, share, share_se, count, count_se, pop_count, pop_count_se) %>% 
  arrange(outcome_var, GEOID, pd, age) %>% 
  data.table()

```

```{r reallocate a portion of five year olds to the school-aged group}
kindy_cutoff <- ifelse(exists("kindergarten_date_cutoff"), 
                       kindergarten_date_cutoff,
                       "09-01")

age5_sch_age_portion <- 
  (ymd(glue("{base_year+1}-12-31")) - ymd(glue("{base_year+1}-{kindy_cutoff}"))) / 365.25
  
age5_sch_age_portion <- as.numeric(age5_sch_age_portion)

age5_portion <- 
  nowcast_elig_counts_added_ages %>% 
  filter(age == "age_5") %>% 
  mutate(count_to_move = age5_sch_age_portion * count,
         se_to_move    = age5_sch_age_portion * count_se,
         var_to_move   = se_to_move^2)

nowcast_elig_counts_final <- 
  nowcast_elig_counts_added_ages %>% 
  merge(age5_portion %>% select(GEOID, outcome_var, cps_base_recency, pd, year, count_to_move, var_to_move),
        by = c("GEOID", "outcome_var", "cps_base_recency", "pd", "year"),
        all.x = TRUE) %>% 
  mutate(count_upd    = case_when(str_detect(age, "3to5|0to5") ~ count - count_to_move,
                                  str_detect(age, "6to12")     ~ count + count_to_move,
                                  TRUE                         ~ count),
         count_se_upd = case_when(str_detect(age, "3to5|0to5") ~ sqrt(count_se^2 - var_to_move),
                                  str_detect(age, "6to12")     ~ sqrt(count_se^2 + var_to_move),
                                  TRUE                         ~ count_se))
```


```{r check on reallocation of a portion of five year olds to the school-aged group, eval = developer_mode}

nowcast_elig_counts_final %>% 
  filter(outcome_var == outcome_var[1],
         cps_base_recency == cps_base_recency[1],
         pd == "nowcast") %>% 
  ggplot(aes(x = count,
             y = count_upd - count)) +
  facet_wrap(~age,
             scales = "free") +
  geom_point()
```


```{r complete reallocation of a portion of five year olds to the school-aged group}
nowcast_elig_counts_final <- 
  nowcast_elig_counts_final %>% 
  select(-count, -count_se) %>% 
  rename(count    = count_upd,
         count_se = count_se_upd)
```


### Aggregate Estimates to Larger Geographies

```{r function to add level of aggregation if not already available}
add_agg_level <- function(ests, agg_level) {
  
  if (!agg_level %in% colnames(ests)) {
    if (agg_level == "ZCTA") {
      geo_merge_data <- 
        geo_crosswalk_zcta %>% 
        transmute(GEOID    = GEOID, 
                  ZCTA     = ZCTA,
                  geo_part = TRLANDPCT)
    } else if (agg_level == "School") {
      geo_merge_data <-
        geo_crosswalk_sd %>%
        transmute(GEOID    = GEOID,
                  School   = school,
                  geo_part = pct_sd)
    } else if (agg_level == "aux_geo_label") {
      geo_merge_data <- 
        geo_crosswalk_aux %>% 
        transmute(GEOID         = GEOID, 
                  aux_geo_label = aux_geo_label, 
                  geo_part      = pct_area)
    } else {
      geo_merge_data <- 
        geo_crosswalk[j = c("GEOID", agg_level), with = FALSE] %>% 
        unique() %>% 
        .[j = geo_part := 1]
    }
    ests <- 
      ests %>% 
      .[cps_base_recency == "most_recent"] %>% 
      # Note: while merge() is typically used throughout this codebase, we use
      # left_join() here because we have a less-common situation of a large
      # many-to-many merge e.g. in the case of merging to zip codes, where there
      # are many duplicates of GEOID in `ests` because of outcome variable, age
      # and time repeats, as well as in `geo_merge_data` given that tracts often
      # do span multiple zip codes. The `allow.cartesian=TRUE` option in merge()
      # was yielding incorrect and puzzling results.
      left_join(geo_merge_data,
                by = "GEOID") %>% 
      data.table()
  }
  
  if (!"geo_part" %in% colnames(ests)) {
    ests <- mutate(ests, geo_part = 1)
  }
  
  return(ests)
}
```


```{r create function to aggregate tract estimates to higher levels}
agg_tracts_up <- function(ests, agg_level) {
  ests %>%
    add_agg_level(agg_level) %>% 
    .[j = .(count        = sumNA(pop_count*share*geo_part),
            count_se     = se_sum(se_product(pop_count*geo_part, share, pop_count_se*geo_part, share_se)),
            pop_count    = sumNA(pop_count*geo_part),
            pop_count_se = se_sum(pop_count_se*geo_part)),
      by = c(agg_level, "age", "pd", "outcome_var")] %>% 
    mutate(share    = count / pop_count,
           share_se = se_proportion(count, pop_count, count_se, pop_count_se))
}
```

```{r implement various levels of geographic aggregation}
# Note -- ZCTA and "aux" calculations may produce a "Detected an unexpected
# many-to-many relationship between `x` and `y`." This is expected, given 
# how this is a feature of crossing geographies.

nowcast_agg_tract <- agg_tracts_up(nowcast_elig_counts_final, "GEOID")
nowcast_agg_zip   <- agg_tracts_up(nowcast_elig_counts_final, "ZCTA")
nowcast_agg_cty   <- agg_tracts_up(nowcast_elig_counts_final, "County")
nowcast_agg_sd    <- agg_tracts_up(nowcast_elig_counts_final, "School")

if (exists("my_aux_geo")) {
  nowcast_agg_aux <- agg_tracts_up(nowcast_elig_counts_final, "aux_geo_label")  
}
```

```{r produce simple output of the aggregates}
my_write.csv <- function(x, suffix) {
  write.csv(x, 
            file = glue("{output_path}Simple elig output by age, period, and outcome -- {suffix}_{my_output_tag}.csv"),
            row.names = FALSE)
}

my_write.csv(nowcast_agg_tract, "by tract")
my_write.csv(nowcast_agg_zip,   "by zcta")
my_write.csv(nowcast_agg_cty,   "by county")
my_write.csv(nowcast_agg_sd,    "by school districts")

if (exists("my_aux_geo")) {
  my_write.csv(nowcast_agg_aux, glue("by {my_aux_geo_desc}"))
}

```


#### Generate Excel Tables with Estimates at Each Geographic Aggregation for CCDF

```{r develop time period indication for output }
# Automate the calculation of the time period
# /!\ This currently assumes that "most_recent" is the chosen sensitivity from 
# 03a. Need to find a way to pass the actual choice from 03a to here. This is not
# complicated, but just needs light planning.

most_recent_range <- 
  most_recent_months %>% 
  sort() %>% 
  paste0("-01") %>% 
  as.Date()
date1 <- most_recent_range[1]
date2 <- most_recent_range %>% .[length(.)]
if (year(date1) == year(date2)) {
  date_range <- paste0(format(date1, "%b"), "-",
                       format(date2, "%b %Y"))
} else {
  date_range <- paste0(format(date1, "%b %Y"), "-",
                       format(date2, "%b %Y"))
}
```


```{r function to output excel sheets for various levels of geographic aggregation}
write_agg_output <- function(outcomes_regex, agg_levels, out_label) {

  ccdf_income_thresh_label <- 
    ifelse(exists("local_custom_thresh_label"),
           local_custom_thresh_label,
           "FPL")
  
  wb <- openxlsx::createWorkbook()
  
  if (exists("excel_front_page_file")) {
    addWorksheet(wb, "Front page")
    xlsx::write.xlsx(get(excel_front_page_file), 
                     wb, 
                     sheetName = "Front Page")
  }
  
  for (lvl in agg_levels) {
    add_sheet <-
      copy(lvl[["agg_table"]]) %>% 
      arrange(get(lvl[["agg_field"]])) %>% 
      setnames(lvl[["agg_field"]], lvl[["sheet_name"]]) %>% 
      filter(pd == "nowcast") %>% 
      # convert age to narrative
      mutate(Age = str_replace(age, "age_(\\d+)to(\\d+)", "Age \\1-\\2"),
             
             #Outcome = str_replace(outcome_var, "^([a-z]+)_.+", "\\1"),
             Outcome = 
               case_when(str_detect(outcome_var, "^ccdf") ~ 
                           str_replace(outcome_var, 
                                       "ccdf_elig_incratio_(\\d+)",
                                       glue("{local_ccdf_name_short} - \\1% {ccdf_income_thresh_label}")),
                         str_detect(outcome_var, "_le50_")  ~ "Below 50% FPL",
                         str_detect(outcome_var, "_le100_") ~ "Below 100% FPL",
                         str_detect(outcome_var, "_le185_") ~ "Below 185% FPL",
                         str_detect(outcome_var, "_le200_") ~ "Below 200% FPL",
                         str_detect(outcome_var, "_le225_") ~ "Below 225% FPL",
                         str_detect(outcome_var, "_le400_") ~ "Below 400% FPL"),
             
             # Calculate bounds, and round
             count_lb = round(count + qnorm(.1)*count_se),
             count_ub = round(count + qnorm(.9)*count_se),
             count    = round(count),
             pop_count = round(pop_count), # This is in order to get "round" values of share
             
             # (Re)calculate share to be consistent with the rounded counts.
             # This is most significant for small geographies, where counts may
             # be small--and thus likely a familiar percentage, or even 0
             share = (count / pop_count) %>% replace_na(0),
             share_se = se_proportion(count, pop_count, count_se, pop_count_se),
             share_lb = pmax(share + qnorm(.1)*share_se, 0) %>% replace_na(0),
             share_ub = pmin(share + qnorm(.9)*share_se, 1) %>% replace_na(0)) %>% 
      dplyr::select(-count_se, -share_se, -pop_count, -pop_count_se) %>% 
      pivot_longer(cols = matches("(count|share)(_|$)")) %>% 
      mutate(stat = case_when(name %like% "count" ~ "#",
                              name %like% "share" ~ "%"),
             calc = case_when(name %like% "_lb" ~ ", lower bound",
                              name %like% "_ub" ~ ", upper bound",
                              TRUE ~ ""),
             
             label = glue("{Age} {Outcome}, {date_range} -- {stat}{calc}")) %>% 
      dplyr::select(-age, -pd, -outcome_var, -Age, -Outcome, -name, -stat, -calc) %>% 
      pivot_wider(names_from = label,
                  values_from = value)
    
    openxlsx::addWorksheet(wb, 
                           sheetName = lvl[["sheet_name"]])
    
    # Write the data to the new sheet
    writeDataTable(wb, 
                   sheet = lvl[["sheet_name"]], 
                   x = add_sheet,
                   colNames = TRUE, 
                   rowNames = FALSE,
                   tableStyle = "TableStyleMedium2")
    
    # Format specified columns as percentage
    addStyle(wb, 
             sheet = lvl[["sheet_name"]], 
             style = createStyle(numFmt = "0.0%"), 
             cols = str_which(cn(add_sheet), "-- %"),
             rows = 1:nrow(add_sheet),
             gridExpand = TRUE)
    
    # Wrap text for header row
    addStyle(wb, 
             sheet = lvl[["sheet_name"]], 
             style = createStyle(wrapText = TRUE), 
             cols = 1:ncol(add_sheet),
             rows = 1,
             gridExpand = TRUE)
    
    # Freeze the top row and leftmost column
    freezePane(wb,
               sheet = lvl[["sheet_name"]],
               firstRow = TRUE,
               firstCol = TRUE)
    
    # Set column widths
    setColWidths(wb, 
                 sheet = lvl[["sheet_name"]], 
                 cols = 2:ncol(add_sheet), 
                 widths = 18)
    
    # Group and hide columns corresponding to upper and lower bounds
    groupColumns(wb,
                 sheet = lvl[["sheet_name"]],
                 cols = str_which(cn(add_sheet), "bound$"),
                 hidden = TRUE)
  }
  
  openxlsx::saveWorkbook(
    wb, 
    file = glue("{output_path}{out_label} eligibility estimates by geography - {my_output_tag}.xlsx"),
    overwrite = TRUE
  )
}
```


```{r write various levels of geographic aggregation out to file for ccdf}

outcomes_out_regex <- "ccdf_elig_incratio_|incpov_le(50|100|200)"

lAgg_for_output <- 
  list(list(agg_table = nowcast_agg_zip,
            agg_field = "ZCTA",
            sheet_name = "Zip Code"),
       list(agg_table = nowcast_agg_cty,
            agg_field = "County",
            sheet_name = "County"))

if (exists("my_aux_geo")) {
  lAgg_for_output[length(lAgg_for_output)+1] <- 
    list(agg_table = nowcast_agg_aux,
         agg_field = "aux_geo_label",
         sheet_name = my_aux_geo_desc)
}

write_agg_output(outcomes_regex = outcomes_out_regex,
                 agg_levels = lAgg_for_output,
                 out_label = local_ccdf_name_short)

```

```{r write various levels of geographic aggregation out to file for le50 100 and 200}
if (exists("my_aux_geo")) {
  write_agg_output(x = nowcast_ests_aux %>% filter(outcome_var %like% "le50"),
                   agg_level = "aux_geo_label",
                   sheet_name = my_aux_geo_desc, 
                   add = FALSE,
                   out_label = "Pov_below_50")
  
  write_agg_output(x = nowcast_ests_aux %>% filter(outcome_var %like% "le100"),
                   agg_level = "aux_geo_label",
                   sheet_name = my_aux_geo_desc, 
                   add = FALSE,
                   out_label = "Pov_below_100")
  
  write_agg_output(x = nowcast_ests_aux %>% filter(outcome_var %like% "le200"),
                   agg_level = "aux_geo_label",
                   sheet_name = my_aux_geo_desc, 
                   add = FALSE,
                   out_label = "Pov_below_200")
}
```


```{r optionally add other custom aggregations}

if (str_detect(my_output_tag, "^IL")) {
  # Adding reporting by an additional level of aggregation for just Illinois
  
  # See this website reference for how counties are grouped within payment regions:
  #   https://www.dhs.state.il.us/page.aspx?item=121213
  
  map_county_to_payreg <- function(cty) {
    case_when(str_detect(cty, "Cook|DeKalb|DuPage|Kane|Kendall|Lake|McHenry") ~ "Group 1A Counties",
              str_detect(cty, "Boone|Champaign|Kankakee|Madison|McLean|Monroe|Ogle|Peoria|Rock Island|Sangamon|St\\. Clair|Tazewell|Whiteside|^Will$|Winnebago|Woodford") ~ "Group 1B Counties",
              TRUE ~ "Group 2 Counties")
  }
  
  nowcast_elig_counts_final_aug <- 
    nowcast_elig_counts_final %>% 
    merge(geo_crosswalk[j = .(GEOID, County)] %>% unique(),
          by = "GEOID",
          all.x = TRUE) %>% 
    mutate(payment_reg = map_county_to_payreg(County))
  if (FALSE) {
    nowcast_elig_counts_final_aug %>% 
      dplyr::select(payment_reg, County) %>% 
      unique() %>% 
      arrange(payment_reg, County)
  }
  
  nowcast_agg_pay <- agg_tracts_up(nowcast_elig_counts_final_aug, "payment_reg") %>% arrange(payment_reg)
  
  for (ccdf_spec in str_subset(nowcast_elig_counts_final$outcome_vars, "ccdf_elig_incratio_")) {
    my_out_label <- 
      str_replace(ccdf_spec,
                  "ccdf_elig_incratio_(\\d+)",
                  "{local_ccdf_name_short} - \\1%")
    
    write_agg_output(x = nowcast_agg_pay %>% filter(outcome_var == ccdf_spec), 
                     agg_level = "payment_reg", 
                     sheet = "Payment Region", 
                     add = TRUE,
                     out_label = my_out_label)
  }
}
```

### Examine Final Estimates

#### Compare Nowcast Estimates vs Baseline

```{r function to compare pre-post changes in aggregates, eval = "my_aux_geo" %in% objects(), results = "asis"}

cat("#### For Auxiliary Geography -- Examine Pre-Post CCDF Changes Directly")

# Generate paired bar at aux level
aux_lvl_ests_long <- 
  ccdf_ests_aux %>% 
  dplyr::select(my_aux_geo_field, ccdf_share_pre, ccdf_share_post) %>% 
  pivot_longer(cols = -my_aux_geo_field) %>% 
  filter(!is.na(my_aux_geo_field))

ggplot(aux_lvl_ests_long,
       aes(x = my_aux_geo_field,
           y = value,
           fill = factor(name, levels = c("ccdf_share_pre", "ccdf_share_post")))) +
  geom_bar(stat = "identity",
           width = 0.5,
           position = position_dodge(width = 0.5)) +
  scale_fill_manual(name = "",
                    breaks = c("ccdf_share_pre", "ccdf_share_post"),
                    labels = c("2021", "Sept-Nov 2022"),
                    values = chHexs[c(2, 4)]) +
  scale_y_continuous(labels = percent) +
  labs(title = case_when(my_output_tag == "IL" ~ "CCAP Eligibility Generally Declines, but Unevenly Across SDAs",
                         TRUE ~ ""),
       x = "",
       y = "") +
  #theme_minimal() +
  myTheme +
  theme(axis.text.x = element_text(angle = 90,
                                   vjust = 0.5,
                                   hjust = 1.0))
```

#### Compare Estimates At Different Levels of Aggregation

```{r examine the dispersion across }

nowcast_agg_zip %>% 
  .[outcome_var %like% "ccdf_elig" & pd == "nowcast"] %>% 
  ggplot(aes(x = share,
             color = str_replace(outcome_var, ".+_(\\d+)$", "\\1%"))) +
  geom_density() +
  facet_wrap(~ age) +
  scale_x_continuous(labels = percent) +
  scale_color_discrete(name = "Income Eligibility Threshold") +
  labs(x = "% CCDF Eligibility") +
  theme_minimal() +
  theme(legend.position = "bottom")
```


```{r check that estimated eligibility is properly ordered across multiple ccdf income cutpoints, results = 'asis'}
if (exists("custom_income_thresh")) {
  
  cat("#### Compare Estimates Across CCDF Income Cutpoints\n\n")  
  
  
  
  plot_data <- 
    nowcast_agg_zip %>% 
    .[outcome_var %like% "ccdf_elig" & pd == "nowcast"] %>% 
    .[j = order := min(share),
      by = ZCTA]
  
  get_zcta_order <- function(z) plot_data[ZCTA == z, min(share)] 
  
  my_plot <- 
    ggplot(plot_data,
           aes(x = reorder(ZCTA, order),
               y = share,
               color = str_replace(outcome_var, ".+_(\\d+)$", "\\1%"))) +
    geom_point(alpha = 0.2) + 
    geom_line() +
    facet_wrap(~ age) +
    scale_y_continuous(labels = percent) +
    scale_color_discrete(name = "Income Eligibility Threshold") +
    labs(x = "ZCTAs, in order of lowest income threshold") +
    theme(legend.position = "bottom",
          axis.text.x = element_blank())
  
  print(my_plot)
}
```



#### Map Levels and Differences

```{r generate static plots}
static_map_val <- function(estimates,
                           geo_level,
                           geo_level_merge_field = geo_level,
                           geo_level_desc = geo_level,
                           outcome,
                           field_desc,
                           plot_stat, # can take values "nowcast" or "diff"
                           save_map = TRUE, 
                           val_limits = NULL,
                           show_legend = TRUE,
                           fill_trans  = "identity") { # an alternative is "sqrt"
  
  ### Prepare estimates -------------------------------------------------------#
  est_plot <- 
    estimates %>% 
    filter(outcome_var %like% outcome) %>% 
    dplyr::select(-count, -count_se, -pop_count, -pop_count_se, -share_se)
  
  est_wide <- 
    est_plot %>% 
    pivot_wider(names_from = pd,
                values_from = share) %>% 
    mutate(diff = nowcast - base,
           Age = str_replace_all(age, ".+(\\d+)to(\\d+)", "Age \\1-\\2"))
  
  ### Join Geographic Data ----------------------------------------------------#
  myShp <- get(glue("{str_to_lower(geo_level)}Shp"))
  est_geo <- 
    est_wide %>% 
    merge(myShp,
          by = geo_level_merge_field) %>% 
    st_as_sf()
  
  ### Set plot options --------------------------------------------------------#
  # See this reference for setting `option` for scale_fill_viridis_c():
  #   https://ggplot2.tidyverse.org/reference/scale_viridis.html
  # See this as a visual reference for viridis color maps:
  #   https://cran.r-project.org/web/packages/viridis/vignettes/intro-to-viridis.html
  color_opt <- ifelse(plot_stat == "nowcast", 
                      "plasma",  # this is roughly yellow-red-purple
                      "viridis") # this is roughly yellow-green-purple
  
  if (plot_stat == "nowcast") {
    measure_label <- glue("Levels of {field_desc}")  
  } else {
    field_desc <- str_replace(field_desc, "\\(", glue("\\({base_year} - "))
    measure_label <- glue("Pct Pt Diff in {field_desc}")  
  }
  
  # Prep outcome description to work with filenaming
  measure_label_out <- 
    measure_label %>% 
    str_replace("<", "Below") %>% 
    str_replace("%", "pct")
  
  ### Generate Map Plot -------------------------------------------------------#
  my_plot <- 
    ggplot() +
    geom_sf(data = est_geo,
            aes_string(fill = plot_stat),
            linewidth = 0.025,
            color = "black")
  
  # # Add PUMA layer if requested
  # if (show_puma){
  #   my_plot <-
  #     my_plot +
  #     geom_sf(data = st_as_sf(pumaShp),
  #           color = "red",
  #           size = 1,
  #           fill = NA)
  # }
  # 
  # # Add aux geo if defined
  # if (show_aux) {
  #   my_plot <- 
  #     my_plot +
  #     geom_sf(data = st_as_sf(auxShp),
  #           color = "black",
  #           size = 0.1,
  #           fill = NA)
  # }
  
  # Finish map
  my_plot <-
    my_plot + 
    scale_fill_viridis_c(name = measure_label,
                         limits = val_limits, 
                         option = color_opt,
                         trans = fill_trans,
                         labels = percent,
                         alpha = .4) +
    facet_wrap(~Age) +
    theme_void() 
  
  # Remove legend if not desired
  if (!show_legend) {
    my_plot <- 
      my_plot +
      theme(legend.position = "none")
  }
      
  if (save_map) {
    ggsave(plot = my_plot,
           filename = glue("{output_path}Map of {measure_label_out} for {geo_level_desc}_{my_output_tag}.png"),
           #width = 7,
           height = 7,
           units = "in")  
  }
  
  return(my_plot)
}
```


```{r map to generate maps for both levels and differences}
static_map_level_diff <- function(plot_stats = c("nowcast", "diff"),
                                  ...) {
  
  for (ps in plot_stats) {
    static_map_val(plot_stat = ps,
                   ...)
  }
}
```


```{r generate static plots of ccdf eligibility in levels and differences}

for (out_var in c("ccdf", "le100", "le200")) {
  out_var_desc <- 
    switch(out_var,
           "ccdf"  = glue("CCAP Eligibility ({date_range})"),
           "le100" = glue("Head Start Eligibility ({date_range})"),
           "le200" = glue("Income <200% FPL ({date_range})"))
  
  static_map_level_diff(estimates = nowcast_agg_zip %>% filter(age == "age_0to5"),
                        geo_level = "ZCTA",
                        outcome = out_var,
                        field_desc = out_var_desc,
                        save_map = TRUE, 
                        #val_limits = c(0, 0.6),
                        show_legend = TRUE)
  
  static_map_level_diff(estimates = nowcast_agg_cty %>% filter(age == "age_0to5"),
                        geo_level = "County",
                        outcome = out_var,
                        field_desc = out_var_desc,
                        save_map = TRUE, 
                        #val_limits = c(0, 0.6),
                        show_legend = TRUE)
  
  static_map_level_diff(estimates = nowcast_agg_sd %>% filter(age == "age_0to5"),
                        geo_level = "School",
                        outcome = out_var,
                        field_desc = out_var_desc,
                        save_map = TRUE, 
                        #val_limits = c(0, 0.6),
                        show_legend = TRUE)
  
  static_map_level_diff(estimates = nowcast_agg_aux %>% filter(age == "age_0to5"),
                        geo_level = "aux",
                        geo_level_merge_field = "aux_geo_label",
                        geo_level_desc = my_aux_geo_desc,
                        outcome = out_var,
                        field_desc = out_var_desc,
                        save_map = TRUE, 
                        #val_limits = c(0, 0.6),
                        show_legend = TRUE) 
}
```

<!-- /!\ Could also consider generating a series of maps to show the logical progression of 
  ## ACS1 (PUMA)                    ... shows basic, baseline data
  -> ACS5 (tract w/PUMA overlay)    ... shows heterogeneity, as a predictor for SAE 
  -> SAE (tract with PUMA overlay)  ... shows SAE result
  -> Now-cast (tract)               ... shows changes
  -> geo aggregation                ... shows conversion to useful basis

-->

```{r compare levels of outcomes}
comp_out <-
  nowcast_agg_aux %>%
    filter(pd == "nowcast" & age == "age_0to5") %>%
    select(aux_geo_label, outcome_var, share) %>% 
    pivot_wider(names_from = "outcome_var",
                values_from = "share")

  ggplot(comp_out,
         aes(x = incpov_le225_post_adj,
             y = get(glue("ccdf_elig_incratio_{local_ccdf_incratio_base}")))) +
  geom_point() +
  geom_abline()
  
  ggplot(comp_out,
         aes(x = incpov_le225_post_adj,
             y = incpov_le100_post_adj)) +
  geom_point() +
  geom_abline()

```

```{r}
nowcast_parallel_counts
```

